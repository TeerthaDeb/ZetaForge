{
  "information": {
    "id": "meta-llama",
    "name": "Llama",
    "description": "Generates text completions using a Hugging Face pipeline with the specified model and prompt.\n\nParameters:\nhf_token (str): The Hugging Face authentication token used to access the model.\nmodel_id (str): The ID of the model to use for text generation.\nprompt (str): The input text to generate completions for.\n\nReturns:\ndict: A dictionary containing the generated output under the key 'llama'.",
    "system_versions": ["0.1"],
    "block_version": "block version number",
    "block_source": "core/blocks/meta-llama",
    "block_type": "compute"
  },
  "inputs": {
    "hf_token": {
      "type": "Any",
      "connections": []
    },
    "model_id": {
      "type": "Any",
      "connections": []
    },
    "prompt": {
      "type": "Any",
      "connections": []
    }
  },
  "outputs": {
    "llama": {
      "type": "Any",
      "connections": []
    }
  },
  "action": {
    "container": {
      "image": "meta-llama-gpu1",
      "version": "latest",
      "command_line": ["python", "-u", "entrypoint.py"]
    }
  },
  "views": {
    "node": {
      "active": "True or False",
      "title_bar": {
        "background_color": "#6b2be0"
      },
      "preview": {},
      "html": "",
      "pos_x": "1045",
      "pos_y": "197",
      "pos_z": "999",
      "behavior": "modal",
      "order": {
        "input": ["hf_token", "model_id", "prompt"],
        "output": ["llama"]
      }
    }
  },
  "events": {}
}
